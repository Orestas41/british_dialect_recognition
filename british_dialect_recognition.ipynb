{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8136872,"sourceType":"datasetVersion","datasetId":4810236}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/orestasdulinskas/british-dialect-recognition?scriptVersionId=186865420\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"![voice recognition](https://cdn-icons-png.flaticon.com/512/1231/1231058.png)","metadata":{}},{"cell_type":"markdown","source":"# British dialect recognition\n---\n## Background\nLanguage, particularly its variations and nuances, plays a crucial role in understanding and appreciating the cultural and social fabrics of regions. English, as spoken in the UK and Ireland, is characterized by a rich tapestry of dialects, each with its distinct phonetic, lexical, and syntactic features. These dialects not only reflect historical and geographical influences but also serve as markers of identity for individuals and communities. The advent of machine learning and data science has opened new avenues for exploring these linguistic variations systematically. This project aims to leverage these technologies to analyze and predict English dialects based on audio recordings, contributing to the broader field of sociolinguistics and dialectology.\n\n## Objectives\nThe primary objective of this project is to train a recurrent neural network (RNN) model capable of predicting the dialect of English spoken by a speaker based on audio recordings. By doing so, the project seeks to:\n1. Identify key linguistic features that distinguish different English dialects in the UK and Ireland.\n2. Develop a robust and accurate machine learning model that can generalize across various speakers and contexts.\n\n## Data\nThe dataset used for this project comprises recordings from speakers across a broad spectrum of dialects from the UK and Ireland. Participants self-identified their dialect from the following categories:\n\n- Irish English\n- Midlands English\n- Northern English\n- Scottish English\n- Southern English\n- Welsh English\n\nTo ensure comprehensive coverage of each dialect's unique features, different elicitation scripts were crafted for each speaker. However, a set of common sentences was included in all scripts to allow for direct comparison across dialects. These scripts were meticulously designed to highlight specific linguistic features pertinent to each dialect, facilitating contrastive analysis. Additionally, pronunciation variants of place names and other lexical items were captured.\n\nEach elicitation line in the dataset is associated with a LINE_ID, an identifier linking the line to its source. This allows for the retrieval of the same line across different speakers and dialects, enabling detailed comparative analysis. The sources for these lines include Wikipedia, The Rainbow Passage, and modified lines from virtual assistant tasks, curated to include target words for accent elicitation while preserving the original content.\n\nBy utilizing this diverse and carefully curated dataset, the project aims to uncover the intricate patterns and distinctive characteristics of English dialects, ultimately leading to a model that can accurately predict dialects based on spoken language.","metadata":{}},{"cell_type":"markdown","source":"# Data Ingestion\n---","metadata":{}},{"cell_type":"code","source":"import os\nimport librosa\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\naccents = ['irish_english_male',\n                  'midlands_english_female',\n                  'midlands_english_male',\n                  'northern_english_female',\n                  'northern_english_male',\n                  'scottish_english_female',\n                  'scottish_english_male',\n                  'southern_english_female',\n                  'southern_english_male',\n                  'welsh_english_female',\n                  'welsh_english_male']\n\ndef load_audio_files(data_dir, accents):\n    \n    audio_data = []\n    labels = []\n    \n    for label, accent in enumerate(accents):\n        folder_path = os.path.join(data_dir, accent)\n        for file_name in os.listdir(folder_path):\n            if file_name.endswith('.wav'):\n                file_path = os.path.join(folder_path, file_name)\n                audio, sample_rate = librosa.load(file_path, sr=16000)\n                audio_data.append(audio)\n                labels.append(label)\n    \n    return audio_data, labels\n\ndata_dir = '/kaggle/input/uk-and-ireland-english-dialect-speech/'\naudio_data, labels = load_audio_files(data_dir, accents)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:48:47.899861Z","iopub.execute_input":"2024-07-04T17:48:47.900805Z","iopub.status.idle":"2024-07-04T17:51:41.343497Z","shell.execute_reply.started":"2024-07-04T17:48:47.900767Z","shell.execute_reply":"2024-07-04T17:51:41.342616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis\n---","metadata":{}},{"cell_type":"markdown","source":"### Dialect distribution","metadata":{}},{"cell_type":"code","source":"number_classes = {}\n\nfor accent in accents:\n    number_classes[accent] = len(os.listdir(data_dir + accent))","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:51:41.345432Z","iopub.execute_input":"2024-07-04T17:51:41.345911Z","iopub.status.idle":"2024-07-04T17:51:41.366488Z","shell.execute_reply.started":"2024-07-04T17:51:41.345868Z","shell.execute_reply":"2024-07-04T17:51:41.365578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport plotly.express as px\n\nsubject = pd.DataFrame.from_dict(number_classes, orient='index', columns=['Count'])\npx.bar(subject, x=subject.index, y='Count', text='Count', template='ggplot2', title='Dialect distribution')","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:51:41.369461Z","iopub.execute_input":"2024-07-04T17:51:41.369748Z","iopub.status.idle":"2024-07-04T17:51:43.861702Z","shell.execute_reply.started":"2024-07-04T17:51:41.369723Z","shell.execute_reply":"2024-07-04T17:51:43.86079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Audio sample lengths","metadata":{}},{"cell_type":"code","source":"import wave\nimport contextlib\n\ndurations = []\n\nfor accent in accents:\n    for i in os.listdir(data_dir + accent + '/'):\n        try:\n            with contextlib.closing(wave.open(data_dir + accent + '/' + i, 'r')) as f:\n                frames = f.getnframes()\n                rate = f.getframerate()\n                durations.append(frames / float(rate))\n        except:\n            pass\n        \npx.histogram(durations, template='ggplot2', title='Audio file lengths', labels={'value':'Audio length in seconds'})","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:53:08.32082Z","iopub.execute_input":"2024-07-04T17:53:08.321712Z","iopub.status.idle":"2024-07-04T17:53:29.4821Z","shell.execute_reply.started":"2024-07-04T17:53:08.321676Z","shell.execute_reply":"2024-07-04T17:53:29.481117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Audio Samples","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport IPython.display as ipd\nfrom IPython.display import display\nplt.style.use('ggplot')\n\ndef sample_data(path, category):\n    plt.figure(figsize=(15,3))\n    data,sample_rate=librosa.load(path)\n    print(category, '\\n')\n    librosa.display.waveshow(data,sr=sample_rate)\n    display(ipd.Audio(path))","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:53:29.483603Z","iopub.execute_input":"2024-07-04T17:53:29.483907Z","iopub.status.idle":"2024-07-04T17:53:29.490442Z","shell.execute_reply.started":"2024-07-04T17:53:29.483881Z","shell.execute_reply":"2024-07-04T17:53:29.489408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = data_dir + accents[0] + '/irm_03397_00650953544.wav'\nsample_data(path, accents[0])","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:53:29.491606Z","iopub.execute_input":"2024-07-04T17:53:29.492018Z","iopub.status.idle":"2024-07-04T17:53:30.066062Z","shell.execute_reply.started":"2024-07-04T17:53:29.491981Z","shell.execute_reply":"2024-07-04T17:53:30.06514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = data_dir + accents[1] + '/mif_02484_01361903134.wav'\nsample_data(path, accents[1])","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:53:30.068586Z","iopub.execute_input":"2024-07-04T17:53:30.069273Z","iopub.status.idle":"2024-07-04T17:53:30.596075Z","shell.execute_reply.started":"2024-07-04T17:53:30.069236Z","shell.execute_reply":"2024-07-04T17:53:30.595161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = data_dir + accents[2] + '/mim_04310_00366760846.wav'\nsample_data(path, accents[2])","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:53:30.597152Z","iopub.execute_input":"2024-07-04T17:53:30.59742Z","iopub.status.idle":"2024-07-04T17:53:31.138131Z","shell.execute_reply.started":"2024-07-04T17:53:30.597397Z","shell.execute_reply":"2024-07-04T17:53:31.137149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = data_dir + accents[3] + '/nof_04310_00012750120.wav'\nsample_data(path, accents[3])","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:53:31.139204Z","iopub.execute_input":"2024-07-04T17:53:31.139484Z","iopub.status.idle":"2024-07-04T17:53:31.606415Z","shell.execute_reply.started":"2024-07-04T17:53:31.139449Z","shell.execute_reply":"2024-07-04T17:53:31.605491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = data_dir + accents[4] + '/nom_09697_01709812810.wav'\nsample_data(path, accents[4])","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:53:31.607631Z","iopub.execute_input":"2024-07-04T17:53:31.607918Z","iopub.status.idle":"2024-07-04T17:53:32.042644Z","shell.execute_reply.started":"2024-07-04T17:53:31.607894Z","shell.execute_reply":"2024-07-04T17:53:32.04174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = data_dir + accents[5] + '/scf_06136_01402841624.wav'\nsample_data(path, accents[5])","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:53:32.043952Z","iopub.execute_input":"2024-07-04T17:53:32.044235Z","iopub.status.idle":"2024-07-04T17:53:32.551146Z","shell.execute_reply.started":"2024-07-04T17:53:32.044211Z","shell.execute_reply":"2024-07-04T17:53:32.550198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = data_dir + accents[6] + '/scm_04310_01623687431.wav'\nsample_data(path, accents[6])","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:53:32.552169Z","iopub.execute_input":"2024-07-04T17:53:32.552432Z","iopub.status.idle":"2024-07-04T17:53:32.986628Z","shell.execute_reply.started":"2024-07-04T17:53:32.552407Z","shell.execute_reply":"2024-07-04T17:53:32.985742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = data_dir + accents[7] + '/sof_07508_00253667648.wav'\nsample_data(path, accents[7])","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:53:32.989711Z","iopub.execute_input":"2024-07-04T17:53:32.990035Z","iopub.status.idle":"2024-07-04T17:53:33.510037Z","shell.execute_reply.started":"2024-07-04T17:53:32.990008Z","shell.execute_reply":"2024-07-04T17:53:33.509085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = data_dir + accents[8] + '/som_07505_00831846630.wav'\nsample_data(path, accents[8])","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:53:33.511229Z","iopub.execute_input":"2024-07-04T17:53:33.511534Z","iopub.status.idle":"2024-07-04T17:53:34.042437Z","shell.execute_reply.started":"2024-07-04T17:53:33.511508Z","shell.execute_reply":"2024-07-04T17:53:34.041579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = data_dir + accents[9] + '/wef_07049_00214407505.wav'\nsample_data(path, accents[9])","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:53:34.043579Z","iopub.execute_input":"2024-07-04T17:53:34.043876Z","iopub.status.idle":"2024-07-04T17:53:34.571892Z","shell.execute_reply.started":"2024-07-04T17:53:34.043849Z","shell.execute_reply":"2024-07-04T17:53:34.57093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = data_dir + accents[10] + '/wem_12484_00567781102.wav'\nsample_data(path, accents[10])","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:53:34.573075Z","iopub.execute_input":"2024-07-04T17:53:34.573368Z","iopub.status.idle":"2024-07-04T17:53:35.114883Z","shell.execute_reply.started":"2024-07-04T17:53:34.573342Z","shell.execute_reply":"2024-07-04T17:53:35.113905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processing\n---","metadata":{}},{"cell_type":"markdown","source":"### Extract audio features","metadata":{}},{"cell_type":"code","source":"def extract_features(audio_data):\n    features = []\n    for audio in audio_data:\n        mfccs = librosa.feature.mfcc(y=audio, sr=16000, n_mfcc=13)\n        features.append(mfccs.T)\n    return features\n\nfeatures = extract_features(audio_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:53:35.116145Z","iopub.execute_input":"2024-07-04T17:53:35.11643Z","iopub.status.idle":"2024-07-04T17:58:13.764242Z","shell.execute_reply.started":"2024-07-04T17:53:35.116404Z","shell.execute_reply":"2024-07-04T17:58:13.762824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\nimport numpy as np\n\nmax_len = max([len(feature) for feature in features])\nX = pad_sequences(features, maxlen=max_len, padding='post', dtype='float32')\ny = np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:58:13.766089Z","iopub.execute_input":"2024-07-04T17:58:13.766743Z","iopub.status.idle":"2024-07-04T17:58:25.74881Z","shell.execute_reply.started":"2024-07-04T17:58:13.7667Z","shell.execute_reply":"2024-07-04T17:58:25.747997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting data into training, validation and test sets","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:58:25.74991Z","iopub.execute_input":"2024-07-04T17:58:25.750574Z","iopub.status.idle":"2024-07-04T17:58:26.179717Z","shell.execute_reply.started":"2024-07-04T17:58:25.750546Z","shell.execute_reply":"2024-07-04T17:58:26.178896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training\n---","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Masking, Bidirectional, LSTM, Dropout, BatchNormalization, Dense\n\ndef build_rnn_model(input_shape, output_dim):\n    model = Sequential()\n    model.add(Masking(mask_value=0.0, input_shape=input_shape))\n    model.add(Bidirectional(LSTM(128, return_sequences=True)))\n    model.add(Dropout(0.5))\n    model.add(LSTM(128, return_sequences=False))\n    model.add(BatchNormalization())\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(output_dim, activation='softmax'))\n    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model\n\ninput_shape = (max_len, 13)\noutput_dim = 11\nmodel = build_rnn_model(input_shape, output_dim)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:58:26.180867Z","iopub.execute_input":"2024-07-04T17:58:26.1812Z","iopub.status.idle":"2024-07-04T17:58:27.36447Z","shell.execute_reply.started":"2024-07-04T17:58:26.181173Z","shell.execute_reply":"2024-07-04T17:58:27.363554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\nearly_stopping = EarlyStopping(monitor='loss', patience=10, min_delta=0.0001, restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, min_lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T17:58:27.365662Z","iopub.execute_input":"2024-07-04T17:58:27.366094Z","iopub.status.idle":"2024-07-04T17:58:27.373401Z","shell.execute_reply.started":"2024-07-04T17:58:27.366059Z","shell.execute_reply":"2024-07-04T17:58:27.372623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train,\n                    y_train,\n                    epochs=200,\n                    batch_size=16,\n                    validation_data=(X_val, y_val),\n                    callbacks=[early_stopping, reduce_lr])","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-04T17:58:27.374727Z","iopub.execute_input":"2024-07-04T17:58:27.375159Z","iopub.status.idle":"2024-07-04T18:08:49.13504Z","shell.execute_reply.started":"2024-07-04T17:58:27.375131Z","shell.execute_reply":"2024-07-04T18:08:49.133708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def performance_graph(history):\n    history_df = pd.DataFrame(history.history)\n    fig, axs = plt.subplots(1, 2, figsize=(15, 4))\n    history_df.loc[2:, ['loss', 'val_loss']].plot(ax=axs[0])\n    history_df.loc[2:, ['accuracy', 'val_accuracy']].plot(ax=axs[1])\n    \n    print((\"Best Validation Loss: {:0.4f}\" +\\\n          \"\\nBest Validation accuracy: {:0.4f}\")\\\n          .format(history_df['val_loss'].min(), \n                  history_df['val_accuracy'].max()))","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:08:49.13595Z","iopub.status.idle":"2024-07-04T18:08:49.136306Z","shell.execute_reply.started":"2024-07-04T18:08:49.136136Z","shell.execute_reply":"2024-07-04T18:08:49.136151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"performance_graph(history)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T18:08:49.137552Z","iopub.status.idle":"2024-07-04T18:08:49.137862Z","shell.execute_reply.started":"2024-07-04T18:08:49.137706Z","shell.execute_reply":"2024-07-04T18:08:49.137718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation\n---","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n\ndef performance_metrics(model, X_test, y_test):\n    \n    preds = model.predict(X_test)\n   \n    preds_labels = preds.argmax(axis=1)\n    \n    target_names = accents\n    \n    print(classification_report(y_test, preds_labels, target_names=target_names), '\\n')\n\n    cf_matrix = confusion_matrix(y_test, preds_labels, normalize='all')\n    fig = px.imshow(pd.DataFrame(cf_matrix, columns=target_names, index=target_names), \n          template='ggplot2', title='Confusion Matrix', aspect='auto', text_auto=True, zmin=0,\n          zmax=1, labels={'0':target_names[0],'1':target_names[1]})\n    fig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"performance_metrics(model, X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction on randomly picked audio samples","metadata":{}},{"cell_type":"code","source":"import random\n\ndef predict_emotion(model, accent):\n    audio_file = data_dir + accent + '/' + random.choice(os.listdir(data_dir + accent))\n    audio, sr = librosa.load(audio_file, sr=16000)\n    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n    X = pad_sequences([mfccs.T], maxlen=max_len, padding='post', dtype='float32')\n    prediction = model.predict(X)\n    predicted_label = np.argmax(prediction, axis=1)\n    print('Audio:', accent, '\\n\\nPrediction:', accents[predicted_label[0]], ' Confidence:', prediction[0][predicted_label[0]], '\\n')\n    display(ipd.Audio(audio_file))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for accent in accents:\n    predict_emotion(model, accent)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}